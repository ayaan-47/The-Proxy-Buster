{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f362e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 297ms/step\n",
      "1/1 [==============================] - 0s 201ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "14/14 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from keras_facenet import FaceNet\n",
    "from mtcnn import MTCNN\n",
    "import joblib\n",
    "\n",
    "# Path to the dataset folder\n",
    "dataset_folder = \"data\"\n",
    "\n",
    "# Load the FaceNet model\n",
    "model = FaceNet()\n",
    "\n",
    "# Check if the SVM model is already saved\n",
    "svm_model_path = \"svm_model.pkl\"\n",
    "if os.path.exists(svm_model_path):\n",
    "    # Load the SVM model\n",
    "    classifier = joblib.load(svm_model_path)\n",
    "    label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "else:\n",
    "    # Initialize arrays to store face embeddings and labels\n",
    "    face_embeddings = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate over subfolders in the dataset folder\n",
    "    for subfolder_name in os.listdir(dataset_folder):\n",
    "        subfolder_path = os.path.join(dataset_folder, subfolder_name)\n",
    "        if not os.path.isdir(subfolder_path):\n",
    "            continue\n",
    "\n",
    "        # Load images from the subfolder\n",
    "        for image_name in os.listdir(subfolder_path):\n",
    "            image_path = os.path.join(subfolder_path, image_name)\n",
    "            if not os.path.isfile(image_path):\n",
    "                continue\n",
    "\n",
    "            # Load and preprocess the image\n",
    "            image = cv2.imread(image_path)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image = cv2.resize(image, (160, 160))  # Resize image to match FaceNet input size\n",
    "\n",
    "            # Extract the face embedding\n",
    "            face_embedding = model.embeddings(np.expand_dims(image, axis=0))[0]\n",
    "\n",
    "            # Add the face embedding and corresponding label to the arrays\n",
    "            face_embeddings.append(face_embedding)\n",
    "            labels.append(subfolder_name)\n",
    "\n",
    "    # Convert labels to numerical representation\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "    # Train a support vector machine (SVM) classifier\n",
    "    classifier = SVC(kernel='linear')\n",
    "    classifier.fit(face_embeddings, labels)\n",
    "\n",
    "    # Save the SVM model and label encoder\n",
    "    joblib.dump(classifier, svm_model_path)\n",
    "    joblib.dump(label_encoder, \"label_encoder.pkl\")\n",
    "\n",
    "# Test the trained model on a new image\n",
    "test_image_path = \"group2.jpg\"\n",
    "test_img = cv2.imread(test_image_path)\n",
    "test_image = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "test_image_resized = cv2.resize(test_image, (160, 160))\n",
    "test_image_resized = cv2.resize(test_img, (160, 160))# Resize image to match FaceNet input size\n",
    "\n",
    "# Detect faces in the test image using MTCNN\n",
    "detector = MTCNN()\n",
    "faces = detector.detect_faces(test_image)\n",
    "\n",
    "# Iterate over detected faces\n",
    "for face in faces:\n",
    "    # Extract the bounding box coordinates\n",
    "    x, y, w, h = face['box']\n",
    "    \n",
    "    # Extract the face region\n",
    "    face_image = test_image[y:y+h, x:x+w]\n",
    "    face_image_resized = cv2.resize(face_image, (160, 160))  # Resize face region to match FaceNet input size\n",
    "\n",
    "    # Extract the face embedding for the face region\n",
    "    test_face_embedding = model.embeddings(np.expand_dims(face_image_resized, axis=0))[0]\n",
    "\n",
    "    # Predict the label for the face region\n",
    "    predicted_label = classifier.predict([test_face_embedding])\n",
    "\n",
    "    # Get the confidence scores for all classes\n",
    "    confidence_scores = classifier.decision_function([test_face_embedding])\n",
    "    max_confidence_index = np.argmax(confidence_scores)\n",
    "    max_confidence_score = confidence_scores[0][max_confidence_index]\n",
    "    \n",
    "    # Convert the predicted label back to the original class name\n",
    "#     predicted_person = label_encoder.inverse_transform(predicted_label)[0]\n",
    "    predicted_person = label_encoder.classes_[predicted_label[0]]\n",
    "\n",
    "    # Determine the confidence threshold\n",
    "    confidence_threshold = 2.3\n",
    "\n",
    "    # Draw rectangle around the face\n",
    "    if max_confidence_score >= confidence_threshold:\n",
    "        text = f\"{predicted_person} ({int((max_confidence_score*100)-100 )}% confidence)\"\n",
    "        color = (0, 255, 0)\n",
    "    else:\n",
    "        text = \"Unknown\"\n",
    "        color = (0, 0, 255)\n",
    "\n",
    "    cv2.rectangle(test_img, (x, y), (x + w, y + h), color, 2)\n",
    "    cv2.putText(test_img, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1)\n",
    "\n",
    "# Display the test image\n",
    "cv2.imshow(\"Test Image\", test_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05ce070d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 8s 1s/step - loss: 2.3779 - accuracy: 0.0486\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 7s 1s/step - loss: 2.2419 - accuracy: 0.1243\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 9s 1s/step - loss: 2.1337 - accuracy: 0.2216\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.9142 - accuracy: 0.3405\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.6525 - accuracy: 0.4811\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.2565 - accuracy: 0.6000\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 7s 1s/step - loss: 1.0468 - accuracy: 0.6324\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.7171 - accuracy: 0.7784\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.5116 - accuracy: 0.8216\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.3491 - accuracy: 0.8703\n",
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "31/31 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras_facenet import FaceNet\n",
    "from mtcnn import MTCNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Function to load images from a directory and assign labels to them\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for subfolder in os.listdir(folder):\n",
    "        subfolder_path = os.path.join(folder, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            for filename in os.listdir(subfolder_path):\n",
    "                img_path = os.path.join(subfolder_path, filename)\n",
    "                image = cv2.imread(img_path)\n",
    "                if image is not None:\n",
    "                    images.append(image)\n",
    "                    labels.append(subfolder)\n",
    "    return images, labels\n",
    "\n",
    "# Load the training dataset\n",
    "train_folder = 'data/train/'\n",
    "train_images, train_labels = load_images_from_folder(train_folder)\n",
    "\n",
    "# Convert labels to unique integer values\n",
    "label_to_id = {label: idx for idx, label in enumerate(set(train_labels))}\n",
    "train_labels = np.array([label_to_id[label] for label in train_labels])\n",
    "\n",
    "# Preprocess the training images\n",
    "train_images = [cv2.resize(image, (160, 160)) for image in train_images]\n",
    "train_images = np.array(train_images) / 255.0\n",
    "\n",
    "# Initialize the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(len(label_to_id), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Check if saved model exists\n",
    "saved_model_path = 'model.h5'\n",
    "if os.path.exists(saved_model_path):\n",
    "    # Load the saved model\n",
    "    model.load_weights(saved_model_path)\n",
    "else:\n",
    "    # Train the model\n",
    "    model.fit(train_images, train_labels, epochs=10, batch_size=32)\n",
    "    # Save the model\n",
    "    model.save_weights(saved_model_path)\n",
    "\n",
    "# Initialize MTCNN for face detection\n",
    "detector = MTCNN()\n",
    "\n",
    "# Function to perform face recognition on test images\n",
    "def recognize_faces(test_image):\n",
    "    # Detect faces in the test image\n",
    "    faces = detector.detect_faces(test_image)\n",
    "\n",
    "    for face in faces:\n",
    "        # Extract the face region\n",
    "        x, y, w, h = face['box']\n",
    "        face_img = test_image[y:y+h, x:x+w]\n",
    "\n",
    "        # Preprocess the face image\n",
    "        face_img = cv2.resize(face_img, (160, 160))\n",
    "        face_img = np.expand_dims(face_img, axis=0) / 255.0\n",
    "\n",
    "        # Perform face recognition\n",
    "        predicted_label = model.predict(face_img)[0]\n",
    "        confidence = np.max(predicted_label)\n",
    "\n",
    "        # Set a threshold for confidence\n",
    "        threshold = 0.1\n",
    "\n",
    "        if confidence > threshold:\n",
    "            # Find the corresponding class label\n",
    "            label_index = np.argmax(predicted_label)\n",
    "            predicted_class = list(label_to_id.keys())[list(label_to_id.values()).index(label_index)]\n",
    "#             text = predicted_class\n",
    "            text = f\"{predicted_class} ({int((confidence*100) )}% confidence)\"\n",
    "        else:\n",
    "            text = 'Unknown'\n",
    "\n",
    "        # Draw rectangle around the face and put text\n",
    "        cv2.rectangle(test_image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(test_image, text, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the test image\n",
    "    cv2.imshow('Face Recognition', test_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Load and recognize faces in test images\n",
    "test_folder = cv2.imread(\"group3.jpg\")\n",
    "recognize_faces(test_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "261931bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "test_folder = cv2.imread(\"ayaanlone.jpg\")\n",
    "recognize_faces(test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cf7137",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
