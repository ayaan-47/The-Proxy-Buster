{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c62e864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "import pickle\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e01b1dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We Have to Run this Cell for Once Only as it will generate the Pickle File for once and all.\n",
    "def createpickle():\n",
    "    namelist = []\n",
    "    file_name = \"namelist.pkl\"\n",
    "    f = open(file_name,'wb')\n",
    "\n",
    "    pickle.dump(namelist,f)\n",
    "    f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f827154",
   "metadata": {},
   "source": [
    "# For Dataset generation Using Web Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44720a78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def datagenerate():    \n",
    "    face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    with open('namelist.pkl', 'rb') as f:\n",
    "        namelist= pickle.load(f)\n",
    "        \n",
    "    name = input(\"Enter Full Name for the Data Generation: \")\n",
    "    namelist.append(name)\n",
    "    id = namelist.index(name)\n",
    "    \n",
    "    a = os.getcwd()\n",
    "    idpath = f'{a}\\\\data\\\\{id}'\n",
    "    if not os.path.exists(idpath):\n",
    "        os.makedirs(idpath)\n",
    "    \n",
    "    def face_cropped(img):\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_classifier.detectMultiScale(gray,1.2,5)\n",
    "        for(x,y,w,h) in faces:\n",
    "            face_cropped = img[y:y+h,x:x+w]\n",
    "            return face_cropped\n",
    "        \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    # cap.set(3, 640) # set video width\n",
    "    # cap.set(4, 480) # set video height\n",
    "    img_id = 0\n",
    "    \n",
    "    while True:\n",
    "        ret,my_frame = cap.read()\n",
    "        \n",
    "        if face_cropped(my_frame) is not None:\n",
    "            img_id+=1\n",
    "            \n",
    "            face = cv2.resize(face_cropped(my_frame),(450,450))\n",
    "            \n",
    "            face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "      \n",
    "            file_path=f\"data/{id}/\"+name+\".\"+str(id)+\".\"+str(img_id)+\".jpg\"\n",
    "            \n",
    "    \n",
    "            cv2.imwrite(file_path,face)\n",
    "            cv2.putText(face,str(img_id),(50,50),cv2.FONT_HERSHEY_COMPLEX,2,(0,255,0),2)\n",
    "            cv2.imshow(\"Generated Face\",face)\n",
    "            \n",
    "        if cv2.waitKey(1)==13 or int(img_id) == 100:\n",
    "            break\n",
    "    with open('namelist.pkl','wb') as f:\n",
    "        pickle.dump(namelist,f)\n",
    "        \n",
    "        \n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79bac34",
   "metadata": {},
   "source": [
    "# For Dataset Generation using an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ab3e4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagegenerate():    \n",
    "    face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    with open('namelist.pkl', 'rb') as f:\n",
    "        namelist= pickle.load(f)\n",
    "        \n",
    "    name = input(\"Enter Full Name for the Data Generation: \")\n",
    "    namelist.append(name)\n",
    "    id = namelist.index(name)\n",
    "    \n",
    "    a = os.getcwd()\n",
    "    idpath = f'{a}\\\\data\\\\{id}'\n",
    "    if not os.path.exists(idpath):\n",
    "        os.makedirs(idpath)\n",
    "        \n",
    "    def face_cropped(img):\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_classifier.detectMultiScale(gray,1.3,5)\n",
    "        for(x,y,w,h) in faces:\n",
    "            face_cropped = img[y:y+h,x:x+w]\n",
    "            return face_cropped\n",
    "        \n",
    "    #cap = cv2.VideoCapture(0)\n",
    "    # cap = cv2.imread(\"tobey.jpg\")\n",
    "    \n",
    "    \n",
    "    img_id = 0\n",
    "    \n",
    "    while True:\n",
    "    #     ret,my_frame = cap.read()\n",
    "        my_frame=cv2.imread(\"rock.jpg\")\n",
    "        \n",
    "        if face_cropped(my_frame) is not None:\n",
    "            img_id+=1\n",
    "            \n",
    "            face = cv2.resize(face_cropped(my_frame),(450,450))\n",
    "            \n",
    "            face = cv2.cvtColor(face,cv2.COLOR_BGR2GRAY)\n",
    "      \n",
    "            file_path=f\"data/{id}/\"+name+\".\"+str(id)+\".\"+str(img_id)+\".jpg\"\n",
    "            \n",
    "    \n",
    "            cv2.imwrite(file_path,face)\n",
    "            cv2.putText(face,str(img_id),(50,50),cv2.FONT_HERSHEY_COMPLEX,2,(0,255,0),2)\n",
    "            cv2.imshow(\"Generated Face\",face)\n",
    "            \n",
    "        if cv2.waitKey(1)==13 or int(img_id) == 50:\n",
    "            break\n",
    "    with open('namelist.pkl','wb') as f:\n",
    "        pickle.dump(namelist,f)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36cb439",
   "metadata": {},
   "source": [
    "# Training the Model with Image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99f7f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer():\n",
    "    # Path for face image database\n",
    "    path = 'data'\n",
    "\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create() \n",
    "    detector = cv2.CascadeClassifier(cv2.data.haarcascades +\"haarcascade_frontalface_default.xml\")\n",
    "    def imagenames(path):\n",
    "    \n",
    "        face_samples=[]\n",
    "        faceids=[]\n",
    "    \n",
    "\n",
    "        for path,subdirnames,filenames in os.walk(path):\n",
    "            for filename in filenames:\n",
    "\n",
    "                id=int(os.path.basename(path))\n",
    "                imagePaths=os.path.join(path,filename)\n",
    "\n",
    "                pilimage = Image.open(imagePaths).convert('L')\n",
    "                \n",
    "                img_numpy = np.array(pilimage,'uint8')\n",
    "            \n",
    "                faces = detector.detectMultiScale(img_numpy)\n",
    "\n",
    "                for (x,y,w,h) in faces:\n",
    "                    face_samples.append(img_numpy[y:y+h,x:x+w])\n",
    "                    faceids.append(id)\n",
    "\n",
    "            \n",
    "    \n",
    "        return face_samples,faceids\n",
    "\n",
    "    print (\"\\nTraining Started.\\n\")\n",
    "    faces,faceids = imagenames(path)\n",
    "    recognizer.train(faces, np.array(faceids))\n",
    "    recognizer.save('trainer/trainer.yml') \n",
    "    print(\"{0} faces trained. Exiting Training Program\".format(len(np.unique(faceids))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90841a74",
   "metadata": {},
   "source": [
    "# Face Recognition (Live Camera) using LPBH Algorithm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92cf0e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def facerecognition():\n",
    "    print('\\nStarting Recognizer....')\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "    recognizer.read('trainer/trainer.yml')\n",
    " \n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades +\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    # Starting realtime video capture\n",
    "    cam = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Define min window size to be recognized as a face\n",
    "\n",
    "    with open('namelist.pkl', 'rb') as f:\n",
    "        names = pickle.load(f)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        ret, img = cam.read()\n",
    "        \n",
    "\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = faceCascade.detectMultiScale( \n",
    "            gray,\n",
    "            scaleFactor = 1.2,\n",
    "            minNeighbors = 5,\n",
    "           )\n",
    "\n",
    "        for(x,y,w,h) in faces:\n",
    "\n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "\n",
    "            id, predic = recognizer.predict(gray[y:y+h,x:x+w])\n",
    "            confidence = int((100*(1-predic/300)))\n",
    "\n",
    "            # Check if confidence is less them 100 ==> \"0\" is perfect match \n",
    "            if (confidence > 77):\n",
    "                id = names[id]\n",
    "               # confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "            else:\n",
    "                id = \"unknown\"\n",
    "               # confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "\n",
    "            cv2.putText(img, str(id),(x+w,y+w),cv2.FONT_HERSHEY_DUPLEX,3,(255,0,0),6)\n",
    "            cv2.putText(img, str(predic),(x,y),cv2.FONT_HERSHEY_DUPLEX,1,(255,0,0),2)\n",
    "\n",
    "        cv2.imshow('camera',img) \n",
    "\n",
    "        k = cv2.waitKey(13) & 0xff \n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "  \n",
    "    print(\"\\nExiting Recognizer.\")\n",
    "    cam.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdc4671",
   "metadata": {},
   "source": [
    "# FACE RECOGNITION IMAGE USING LBPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "331b8e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def facerecognitionimage():\n",
    "    print('\\nStarting Recognizer....')\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "    recognizer.read('trainer/trainer.yml')\n",
    " \n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades +\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "\n",
    "\n",
    "    with open('namelist.pkl', 'rb') as f:\n",
    "        names = pickle.load(f)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        img = cv2.imread(\"images.jpg\")\n",
    "        \n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        faces = faceCascade.detectMultiScale( \n",
    "            gray,\n",
    "            scaleFactor = 1.2,\n",
    "            minNeighbors = 5,\n",
    "#             minSize = (int(minW), int(minH)),\n",
    "           )\n",
    "\n",
    "        for(x,y,w,h) in faces:\n",
    "\n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "\n",
    "            id, predic = recognizer.predict(gray[y:y+h,x:x+w])\n",
    "#            \n",
    "            confidence = int((100*(1-predic/300)))\n",
    "#             confidence = round(confidence,2)\n",
    "\n",
    "            # Check if confidence is less them 100 ==> \"0\" is perfect match\n",
    "            if (confidence > 77):\n",
    "                id = names[id]\n",
    "               # confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "            else:\n",
    "                id = \"unknown\"\n",
    "               # confidence = \"  {0}%\".format(round(100 - confidence))\n",
    "\n",
    "            cv2.putText(img, str(id),(x,y+w),cv2.FONT_HERSHEY_DUPLEX,2,(255,0,0),2)\n",
    "            cv2.putText(img, str(confidence),(x,y),cv2.FONT_HERSHEY_DUPLEX,1,(255,0,0),2)\n",
    "\n",
    "        cv2.imshow('camera',img) \n",
    "\n",
    "        k = cv2.waitKey(13) & 0xff \n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "  \n",
    "    print(\"\\nExiting Recognizer.\")\n",
    "    \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d43d449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Create Pickle File \n",
      "2. Generate Dataset (Live Camera) \n",
      "3. Generate Dataset(Images) \n",
      "4. Train Data \n",
      "5. Face Recognition (Live Camera) \n",
      "6. Face Recognition (Image)  \n",
      "7. Exit \n",
      "7\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "while(c!= 7):\n",
    "    c = int(input(\"\\n1. Create Pickle File \\n2. Generate Dataset (Live Camera) \\n3. Generate Dataset(Images) \\n4. Train Data \\n5. Face Recognition (Live Camera) \\n6. Face Recognition (Image)  \\n7. Exit \\n\"))\n",
    "    if c == 1 :\n",
    "        createpickle()\n",
    "    if c == 2:\n",
    "        datagenerate()\n",
    "    if c == 3:\n",
    "        imagegenerate()\n",
    "    if c == 4:\n",
    "        trainer()\n",
    "    if c == 5:\n",
    "        facerecognition()\n",
    "    if c == 6:\n",
    "        facerecognitionimage()\n",
    "    if c == 7:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "629557ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mister Maker\n"
     ]
    }
   ],
   "source": [
    "print(\"Mister Maker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c47d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
